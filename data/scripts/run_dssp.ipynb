{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The notebook for running DSSP on selected wild-mutation pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import DSSP\n",
    "from Bio.PDB import PDBParser\n",
    "import warnings\n",
    "from Bio import BiopythonWarning\n",
    "import pandas as pd\n",
    "from Bio.PDB import PDBIO\n",
    "from Bio.PDB import Dice\n",
    "import numpy as np\n",
    "import Bio\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in this demo we are using the windows version of dssp (.exe). You may use the dssp on other platform as long as you change the envriment settings. Also you need to make sure you have all the pdb files downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "residue_max_acc = { 'A': 106.0, 'R': 248.0, 'N': 157.0,\n",
    "                   'D': 163.0, 'C': 135.0, 'Q': 198.0, \n",
    "                   'E': 194.0, 'G': 84.0, 'H': 184.0, \n",
    "                   'I': 169.0, 'L': 164.0, 'K': 205.0, \n",
    "                   'M': 188.0, 'F': 197.0, 'P': 136.0, \n",
    "                   'S': 130.0, 'T': 142.0, 'W': 227.0, \n",
    "                   'Y': 222.0, 'V': 142.0, 'X':169.6 } \n",
    "\n",
    "class Chain_filter:\n",
    "    def __init__(self, chain_id):\n",
    "        self.chain_id = chain_id\n",
    "    ## accept all model\n",
    "    def accept_model(self, model):\n",
    "        return 1\n",
    "    ## accept the chains in the group\n",
    "    def accept_chain(self, chain): \n",
    "        if chain.get_id() in self.chain_id: \n",
    "            return 1\n",
    "        return 0\n",
    "    # accept all residue in the chain\n",
    "    def accept_residue(self, residue): \n",
    "        return 1\n",
    "    # accept all atoms\n",
    "    def accept_atom(self, atom):\n",
    "        return 1\n",
    "    \n",
    "def extract_chain2pdb(structure, chain_ids, filename):\n",
    "    sel = Chain_filter(chain_ids) \n",
    "    pdbio = PDBIO() \n",
    "    pdbio.set_structure(structure) \n",
    "    pdbio.save(filename, sel) \n",
    "\n",
    "def calculate_sasa(directory,select_mutation_num=None,select_chain_num=None):\n",
    "    \"\"\"\n",
    "    Read in the csv file with a list of wildtypes and mutations.\n",
    "    Calculate the a pair of Delta_SASA for each protei; also calculate the Delta Delta_SASA (wt - mut)\n",
    "    return a dataframe containing the information\n",
    "    \"\"\"\n",
    "    warnings.simplefilter('ignore',BiopythonWarning)\n",
    "    parser = PDBParser()\n",
    "    result = []\n",
    "    \n",
    "    # read in the pairs file\n",
    "    # notice that chains are the same for each pairs of the protein inside the file\n",
    "    wt_mu_pair = pd.read_csv(directory,index_col=0).loc[0:4] \n",
    "    # because in the following the selection mechanism is not clear, I selected first four item according to results\n",
    "    #print(wt_mu_pair)\n",
    "\n",
    "#    if select_mutation_num!=None:\n",
    "#        wt_mu_pair = wt_mu_pair.loc[wt_mu_pair.mutation_num == select_mutation_num,:]\n",
    "    \n",
    "#    if select_chain_num!=None:\n",
    "#        wt_mu_pair = wt_mu_pair.loc[wt_mu_pair.chain_num == select_chain_num,:]\n",
    "        \n",
    "    track = 0\n",
    "    total = wt_mu_pair.shape[0]\n",
    "    \n",
    "    for keys, vals in wt_mu_pair.iterrows():\n",
    "    #    print(keys)\n",
    "    #    print(vals)\n",
    "        # obtian the directory to the wildtype/mutant files\n",
    "        wt_name = vals['wildtype']\n",
    "        mu_name = vals['mutant']\n",
    "        \n",
    "        # specify the pdb files directory here\n",
    "        wt_file = './dssp/pdb/pdb' + wt_name+'.ent'\n",
    "        mu_file = './dssp/pdb/pdb' + mu_name+'.ent'\n",
    "        \n",
    "        # get the structure of complex\n",
    "        wt_struc = parser.get_structure(wt_name, wt_file)\n",
    "        mu_struc = parser.get_structure(mu_name, mu_file)\n",
    "\n",
    "        try:\n",
    "            # find the dssp result of the complex\n",
    "            wt_dssp = DSSP(wt_struc[0], wt_file, 'dssp.exe', file_type='PDB') #first model is stucture[0]\n",
    "            # in case there are failure\n",
    "            while len(wt_dssp)==0:\n",
    "                wt_dssp = DSSP(wt_struc[0], wt_file, 'dssp.exe', file_type='PDB')\n",
    "\n",
    "            mu_dssp = DSSP(mu_struc[0], mu_file, 'dssp.exe', file_type='PDB')\n",
    "            # in case there are failure\n",
    "            while len(mu_dssp)==0:\n",
    "                mu_dssp = DSSP(mu_struc[0], mu_file, 'dssp.exe', file_type='PDB')\n",
    "        except:\n",
    "            print(\"The following pair has corrupted pdb:\", wt_name, mu_name)\n",
    "            continue\n",
    "        \n",
    "    #    \n",
    "        # find the total sasa of the complex\n",
    "        Total_SASA_wt = np.sum([item[3]*residue_max_acc[item[1]] for item in wt_dssp if item[1]!='X'])\n",
    "        Total_SASA_mu = np.sum([item[3]*residue_max_acc[item[1]] for item in mu_dssp if item[1]!='X'])\n",
    "        #print(item[3] for item in wt_dssp)\n",
    "\n",
    "        # get the number of chains and divide them into groups\n",
    "        chain_count = len(wt_struc[0])\n",
    "        first_group = int(chain_count/2)\n",
    "        index = 0\n",
    "        group1 = []\n",
    "        group2 = []\n",
    "        for chain in wt_struc[0]:\n",
    "            if index < first_group:\n",
    "                group1.append(chain.get_id())\n",
    "            else:\n",
    "                group2.append(chain.get_id())\n",
    "            index += 1\n",
    "    \n",
    "        Chain_in_g1 = ''.join(group1) \n",
    "        Chain_in_g2 = ''.join(group2)\n",
    "        \n",
    "            \n",
    "        if len(group2) == 0 or len(group1)==0 or chain_count <= 1:\n",
    "            continue \n",
    "        \n",
    "        try:\n",
    "            ## wild type\n",
    "            # filter to group 1\n",
    "            wt_g1_struc = parser.get_structure(wt_name, wt_file)\n",
    "            extract_chain2pdb(wt_g1_struc,group1, 'temp.ent') #Write a Structure object (or a subset of a Structure object) as a PDB file.\n",
    "            wt_g1_dssp = DSSP(wt_g1_struc[0],'temp.ent','dssp.exe', file_type='PDB')\n",
    "            while len(wt_g1_dssp)==0:\n",
    "                wt_g1_dssp = DSSP(wt_g1_struc[0], 'temp.ent', 'dssp.exe', file_type='PDB')\n",
    "\n",
    "            SASA_wt_g1 = np.sum([item[3]*residue_max_acc[item[1]] for item in wt_g1_dssp if item[1]!='X'])\n",
    "\n",
    "            # filter to group 2\n",
    "            wt_g2_struc = parser.get_structure(wt_name, wt_file)\n",
    "            extract_chain2pdb(wt_g2_struc,group2, 'temp.ent')\n",
    "            wt_g2_dssp = DSSP(wt_g2_struc[0],'temp.ent','dssp.exe', file_type='PDB')\n",
    "            while len(wt_g2_dssp)==0:\n",
    "                wt_g2_dssp = DSSP(wt_g2_struc[0], 'temp.ent', 'dssp.exe', file_type='PDB')\n",
    "\n",
    "            SASA_wt_g2 = np.sum([item[3]*residue_max_acc[item[1]] for item in wt_g2_dssp if item[1]!='X'])\n",
    "\n",
    "            ## mutant\n",
    "            # filter to group 1\n",
    "            mu_g1_struc = parser.get_structure(mu_name, mu_file)\n",
    "            extract_chain2pdb(mu_g1_struc,group1, 'temp.ent')\n",
    "            mu_g1_dssp = DSSP(mu_g1_struc[0],'temp.ent','dssp.exe', file_type='PDB')\n",
    "            while len(mu_g1_dssp)==0:\n",
    "                mu_g1_dssp = DSSP(mu_g1_struc[0], 'temp.ent', 'dssp.exe', file_type='PDB')\n",
    "\n",
    "            SASA_mu_g1 = np.sum([item[3]*residue_max_acc[item[1]] for item in mu_g1_dssp if item[1]!='X'])\n",
    "\n",
    "            # filter to group 2\n",
    "            mu_g2_struc = parser.get_structure(mu_name, mu_file)\n",
    "            extract_chain2pdb(mu_g2_struc,group2, 'temp.ent')\n",
    "            mu_g2_dssp = DSSP(mu_g2_struc[0],'temp.ent','dssp.exe', file_type='PDB')\n",
    "            while len(mu_g2_dssp)==0:\n",
    "                mu_g2_dssp = DSSP(mu_g2_struc[0], 'temp.ent', 'dssp.exe', file_type='PDB')\n",
    "\n",
    "            SASA_mu_g2 = np.sum([item[3]*residue_max_acc[item[1]] for item in mu_g2_dssp if item[1]!='X'])\n",
    "        except:\n",
    "            SASA_wt_g1 = np.nan\n",
    "            SASA_wt_g2 = np.nan\n",
    "            SASA_mu_g1 = np.nan\n",
    "            SASA_mu_g2 = np.nan\n",
    "            print(\"The following pair cause error in DSSP:\", wt_name, mu_name)\n",
    "        \n",
    "        result.append( (wt_name,mu_name,\n",
    "                        Total_SASA_wt,SASA_wt_g1,SASA_wt_g2,\n",
    "                        Total_SASA_mu,SASA_mu_g1,SASA_mu_g2,\n",
    "                        Chain_in_g1,Chain_in_g2))\n",
    "        track += 1\n",
    "        sys.stdout.write(\"\\r\"+str(track)+'/'+str(total)+\" done.\")\n",
    "        sys.stdout.flush()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this demo, we use the constructed wild-mutant pairs with 1,2 or 3 mutations from PDB. Please refer to our paper for how we use sequence alignment to generate the wild-mutant pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 done."
     ]
    }
   ],
   "source": [
    "res = calculate_sasa('./dssp/wt_mu_pairs.csv',select_mutation_num=1,select_chain_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  wt_name mu_name  Total_SASA_wt  SASA_wt_g1  SASA_wt_g2  Total_SASA_mu  \\\n",
      "0    10gs    1md4        17797.0      9785.0      9785.0        17597.0   \n",
      "1    10gs    3hjo        17797.0      9785.0      9785.0        18250.0   \n",
      "2    10gs    3ie3        17797.0      9785.0      9785.0        18099.0   \n",
      "3    117e    1e6a        22598.0     12174.0     12468.0        22407.0   \n",
      "4    117e    1huk        22598.0     12174.0     12468.0        23418.0   \n",
      "\n",
      "   SASA_mu_g1  SASA_mu_g2 Chain_in_G1 Chain_in_G2  \n",
      "0     10090.0     10079.0           A           B  \n",
      "1     10511.0     10406.0           A           B  \n",
      "2     10386.0     10325.0           A           B  \n",
      "3     12287.0     12127.0           A           B  \n",
      "4     12508.0     12959.0           A           B  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(res, columns=['wt_name','mu_name',\n",
    "                        'Total_SASA_wt','SASA_wt_g1','SASA_wt_g2',\n",
    "                        'Total_SASA_mu','SASA_mu_g1','SASA_mu_g2',\n",
    "                        'Chain_in_G1','Chain_in_G2'])\n",
    "print(df)                        \n",
    "# df.to_csv('./dssp/dssp_sasa.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
